# LLM API Integration with Gemini Model

This repository contains my personal implementation and explanation of how to integrate with Large Language Models (LLMs) using the Gemini model API.
All examples are provided in both TypeScript/JavaScript and Python so you can learn integration patterns across languages.

## Repository Structure

- `ts/` - TypeScript/JavaScript implementation
- `python/` - Python implementation

## Purpose

This repository is meant as a practical learning guide showing how to:
- Set up API connections with the Gemini model.
- Send requests and handle responses.
- Implement various features using the LLM API.
- Compare implementations between TypeScript/JavaScript and Python.

Unlike just copying docs, I explain my own thought process and approach, so, the code is easy to follow and actually educational.

## Why This Matters

LLM APIs are the building blocks for AI products:
- Every AI app (chatbots, agents, copilots) starts with an API call.
- Understanding request/response flows is the foundation before adding memory, RAG, or agents.
- Being able to switch between Python (backend) and TypeScript (frontend/full-stack) makes you flexible as a developer.
- This repo = my step one toward mastering AI Engineering / AI Product Development.

## About This Repo
This is part of my learning journey into AI Engineering.
I believe in learning by building, so, everything here is explained in a way that helps others learn too.

If youâ€™re also exploring LLMs, I hope this helps you get started faster!